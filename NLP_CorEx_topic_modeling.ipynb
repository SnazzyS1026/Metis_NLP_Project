{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc9bd98",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a016a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocessing Tools\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Document-Term Matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Topic Modeling\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a6c63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well.</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Rating    Date Reviewer_Location  \\\n",
       "0  670772142       4  2019-4         Australia   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                     Reviews  \\\n",
       "0  If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well.    \n",
       "\n",
       "                Branch Sentiment   Score  \n",
       "0  Disneyland_HongKong  Positive  0.7069  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the display constraints to be able to read entire reviews\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# open pickle file with sentiment and score\n",
    "df = pd.read_pickle('df_sentiment_score_pkl')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fa32d",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51a0f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670772142</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>Australia</td>\n",
       "      <td>if you ve ever been to disneyland anywhere you ll find disneyland hong kong very similar in the layout when you walk into main street  it has a very familiar feel  one of the rides  its a small world  is absolutely fabulous and worth doing  the day we visited was fairly hot and relatively busy but the queues moved fairly well</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Rating    Date Reviewer_Location  \\\n",
       "0  670772142       4  2019-4         Australia   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                     Reviews  \\\n",
       "0  if you ve ever been to disneyland anywhere you ll find disneyland hong kong very similar in the layout when you walk into main street  it has a very familiar feel  one of the rides  its a small world  is absolutely fabulous and worth doing  the day we visited was fairly hot and relatively busy but the queues moved fairly well     \n",
       "\n",
       "                Branch Sentiment   Score  \n",
       "0  Disneyland_HongKong  Positive  0.7069  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "df['Reviews'] = df.Reviews.map(alphanumeric).map(punc_lower)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3cce09",
   "metadata": {},
   "source": [
    "# Topic Modeling - CorEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e46846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=2500,\n",
    "                             stop_words='english', \n",
    "                             token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "doc_word = vectorizer.fit_transform(df.Reviews)\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec0ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37547, 2500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4ce463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accurate',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actors',\n",
       " 'actual']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ce90df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corextopic.corextopic.Corex at 0x1ca2d72bfa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an unsupervised topic model with CorEx without the use of anchor words\n",
    "topic_model = ct.Corex(n_hidden= 10,\n",
    "                       words=words, \n",
    "                       seed=1)\n",
    "\n",
    "topic_model.fit(doc_word,         \n",
    "                words= words,     \n",
    "                docs= df.Reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b258f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: people, way, money, told, think, know, said, let, rude, thing\n",
      "1: food, hotel, paris, queues, queue, good, staff, parks, stayed, expensive\n",
      "2: day, park, did, got, minutes, rides, hour, went, didn, hours\n",
      "3: main, king, street, small, train, castle, lion, parade, hong, story\n",
      "4: disney, just, like, disneyland, really, world, magic, experience, going, year\n",
      "5: mountain, space, pirates, thunder, jones, ride, indiana, caribbean, peter, star\n",
      "6: water, bring, snacks, buy, drinks, need, outside, walking, free, sit\n",
      "7: time, line, wait, make, early, don, want, times, plan, long\n",
      "8: characters, mickey, meet, breakfast, character, minnie, lunch, mouse, princess, old\n",
      "9: fast, pass, passes, use, california, adventure, haunted, mansion, lines, hopper\n"
     ]
    }
   ],
   "source": [
    "# Topics without anchored words\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb88626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create semi-supervised topic model with CorEx with the use of anchor words\n",
    "\"\"\"\n",
    "The anchors we'll use are:\n",
    "\n",
    "1. disneyland, disney, california\n",
    "2. disneyland, paris\n",
    "3. disneyland, hong kong\n",
    "4. disney, food\n",
    "\n",
    "\"\"\"\n",
    "topic_model2 = ct.Corex(n_hidden= 6,\n",
    "                       words=words,  \n",
    "                       seed=1)\n",
    "\n",
    "topic_model2.fit(doc_word,\n",
    "                words= words,\n",
    "                docs= df.Reviews,\n",
    "                anchors=[\n",
    "                         ['disneyland', 'disney', 'california'],\n",
    "                         ['disneyland', 'disney', 'paris'],\n",
    "                         ['disneyland', 'disney', 'hong', 'kong'],\n",
    "                         ['disney', 'food']],\n",
    "                anchor_strength=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50ea3960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: disneyland, california, disney, adventure, world, hopper, southern, anaheim, original, radiator\n",
      "1: disney, paris, walt, florida, disneyland, downtown, orlando, smaller, fan, euro\n",
      "2: disneyland, disney, hong, kong, compared, mtr, hk, unique, tokyo, version\n",
      "3: food, expensive, disney, drinks, drink, quality, prices, options, bring, overpriced\n",
      "4: ride, park, day, people, just, time, rides, did, fast, minutes\n",
      "5: hotel, characters, main, good, mickey, parade, really, queue, small, castle\n"
     ]
    }
   ],
   "source": [
    "# Topics with anchored words\n",
    "topics2 = topic_model2.get_topics()\n",
    "\n",
    "for n,topic in enumerate(topics2):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abf319",
   "metadata": {},
   "source": [
    "# More preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a88adee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Loading Stopwords into a list\n",
    "nltk.download('stopwords')\n",
    "NLTK_stop_words_list = stopwords.words('english')\n",
    "\n",
    "# Adding new stop words\n",
    "add_stop_words_list = ['disneyland', 'disney']\n",
    "\n",
    "final_stop_words_list = (NLTK_stop_words_list + add_stop_words_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a54f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vectorizer2 = CountVectorizer(max_features=2500,\n",
    "                             stop_words=final_stop_words_list,\n",
    "                             token_pattern=\"\\\\b[a-z][a-z]+\\\\b\",\n",
    "                             binary=True)\n",
    "doc_word2 = vectorizer2.fit_transform(df.Reviews)\n",
    "words2 = list(np.asarray(vectorizer2.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82f28e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<corextopic.corextopic.Corex at 0x1bf0a8e6190>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an unsupervised topic model with CorEx without the use of anchor words\n",
    "topic_model3 = ct.Corex(n_hidden= 10,\n",
    "                       words=words2, \n",
    "                       seed=1)\n",
    "\n",
    "topic_model3.fit(doc_word2,         \n",
    "                words= words2,     \n",
    "                docs= df.Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89570714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: people, would, us, could, money, think, told, another, going, know\n",
      "1: one, day, park, minutes, got, hour, tickets, hours, way, two\n",
      "2: get, fast, pass, time, use, line, early, wait, go, passes\n",
      "3: hotel, paris, queues, staff, queue, parks, stayed, studios, half, children\n",
      "4: characters, mickey, main, see, meet, street, breakfast, character, lunch, old\n",
      "5: like, even, first, back, many, years, last, trip, never, made\n",
      "6: show, parade, rides, fireworks, also, night, really, castle, went, well\n",
      "7: mountain, space, pirates, jones, ride, thunder, indiana, caribbean, haunted, mansion\n",
      "8: food, water, take, expensive, around, good, snacks, drinks, eat, bring\n",
      "9: kong, hong, train, king, lion, small, story, toy, grizzly, mystic\n"
     ]
    }
   ],
   "source": [
    "# Topics without anchored words\n",
    "topics3 = topic_model3.get_topics()\n",
    "for n,topic in enumerate(topics3):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b60849cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create semi-supervised topic model with CorEx with the use of anchor words\n",
    "\"\"\"\n",
    "The anchors we'll use are:\n",
    "\n",
    "1. park, california\n",
    "2. park, paris\n",
    "3. park, hong kong\n",
    "4. park, food\n",
    "\n",
    "\"\"\"\n",
    "topic_model4 = ct.Corex(n_hidden= 6,\n",
    "                       words=words2,  \n",
    "                       seed=1)\n",
    "\n",
    "topic_model4.fit(doc_word2,\n",
    "                words= words2,\n",
    "                docs= df.Reviews,\n",
    "                anchors=[\n",
    "                         ['park', 'california'],\n",
    "                         ['park', 'paris'],\n",
    "                         ['park', 'hong', 'kong'],\n",
    "                         ['food']],\n",
    "                anchor_strength=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb45dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: park, california, theme, hopper, clean, amusement, ocean, original, history, navigate\n",
      "1: park, paris, would, people, us, parks, could, hour, staff, two\n",
      "2: park, hong, kong, smaller, maintained, smallest, subway, attractive, senior, organized\n",
      "3: food, expensive, drinks, drink, quality, prices, options, overpriced, priced, pricey\n",
      "4: ride, get, one, mountain, time, day, rides, also, go, space\n",
      "5: hotel, take, around, show, see, good, characters, queue, parade, want\n"
     ]
    }
   ],
   "source": [
    "# Topics with anchored words\n",
    "topics4 = topic_model4.get_topics()\n",
    "\n",
    "for n,topic in enumerate(topics4):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print(f'{n}: {\", \".join(topic_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51d1cb",
   "metadata": {},
   "source": [
    "# More Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda1d68",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ef73e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31200/3149537424.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmwe_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMWETokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hong'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kong'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmwe_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmwe_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\metis\\lib\\site-packages\\nltk\\tokenize\\mwe.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m     94\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "# Use a multi-word tokenizer to link words\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "mwe_tokenizer = MWETokenizer(['hong', 'kong'])\n",
    "mwe_tokens = pd.DataFrame(mwe_tokenizer.tokenize(word_tokenize(doc) for doc in corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
